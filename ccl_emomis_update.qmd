---
title: "Effects of Misinformation on Online Discussions"
author: "Jula Luehring"
subtitle: "CCL Meeting"
date: "5 June 2024"
format: 
  revealjs: 
    seal: false
    transition: "slide"
    theme: [default, custom.scss] #custom style file
    #incremental: true
    aspect-ratio: 16:9
    slide-number: true
    #footer: "@lue_jula" 
title-slide-attributes:
    data-background-color: "#2A76DD" #univie color
    data-background-size: cover
logo: "logos/uni_wien_logo_blue.jpg"
editor: visual #visual editor
---

## Emotions and Misinformation

-   Misinformation as inaccurate information

    -   Symptom of a partisan information ecosystem

-   Missing link in partisan-based processing: emotions

    -   Signals to select, process and memorize information

    -   But also hinder systematic processing

$\rightarrow$ In the context of misinformation, arousing emotions may reinforce partisan-based processing

::: footer
Altay et al., [2023](https://doi.org/10.1177/20563051221150412); Ecker et al., [2023](https://www.nature.com/articles/s44159-021-00006-y); Martel et al. [2020](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7539247/); Wardle & Derakhshan, [2017](http://tverezo.info/wp-content/uploads/2017/11/PREMS-162317-GBR-2018-Report-desinformation-A4-BAT.pdf)
:::

::: notes
-   So when we talk about misinformation, we usually refer to inaccurate information, regardless of the intention.

-   Despite concerns about misinformation, it now seems as a symptom of a clustered information ecosystem where few people are exposed to misinformation, while most people have partisan information diets, including decontextualized but not completely inaccurate information

-   In this process, a missing link are emotions

-   While arousing, mobilizing emotions signal us to better select, process and memorize vital information

-   Which, in theory, is good, they can also hinder systematic processing

-   In the case of misinformation, arousing emotions may therefore reinforce partisan-based processing
:::

# Do emotions make people believe in misinformation?

## Emotional state

::: columns
::: {.column width="35%"}
<br>

-   Replication study

-   False/accurate COVID-19 news headlines

-   Austria 2021

-   *N* = 422
:::

::: {.column width="60%"}
<br> <br>

![](images/Martel.png){width="1000"}
:::
:::

$\rightarrow$ No effects of emotions on misinformation susceptibility

::: footer
Luehring\*, Shetty\*, et al., [2023](https://psyarxiv.com/udqms/); Martel et al., [2020](https://link.springer.com/article/10.1186/s41235-020-00252-3)
:::

## Emotional response

::: columns
::: {.column width="35%"}
-   In response to false news:
    -   More anger
    -   Less joy

ðŸ—¯ *"Bullshit", "Fake"*

:::

::: {.column width="60%"}
![](images/emo_diff_plot_color.svg){width="500"}
:::
:::

::: footer
Luehring\*, Shetty\*, et al., [2023](https://psyarxiv.com/udqms/)
:::

## How do emotions interact with discernment?

![](images/curvi-linear.svg){width="1000"}

-   People with **good and bad discernment** got angry

$\rightarrow$ Function of emotions depends on existing beliefs

::: footer
Luehring\*, Shetty\*, et al., [2023](https://psyarxiv.com/udqms/); Van Damme & Smets, [2014](https://psycnet.apa.org/record/2013-39652-001)
:::

# Misinformation on social media

## Social groups and collective emotions

-   Moralizing and arousing content gets high engagement

-   Misinformation: more negative and conflictual

    -   **But:** only 1-6% in 5 studies from 2016-2019
    -   Elite and ordinary partisan superspreaders

::: columns
::: {.column width="50%"}
$\rightarrow$ Misinformation is embedded in intergroup dynamics

$\rightarrow$ Secondary effects?
:::

::: {.column width="50%"}
![Nikolov et al., [2021](https://misinforeview.hks.harvard.edu/wp-content/uploads/2021/02/nikolov_partisanship_vulnerability_misinformation_20210215.pdf)](images/Nikolov.png){width="600"}
:::
:::

::: footer
Bail, [2021](https://press.princeton.edu/books/hardcover/9780691203423/breaking-the-social-media-prism); Baribi et al., [2024](https://www.science.org/doi/10.1126/science.adl4435); Leach & Zeineddine, [2021](https://link.springer.com/10.1007/s42761-021-00051-z); Mosleh et al. [2024](https://doi.org/10.1093/pnasnexus/pgae111); Robertson et al., [2023](https://www.nature.com/articles/s41586-023-06078-5); Zollo et al., [2015](https://dx.plos.org/10.1371/journal.pone.0138740)
:::

::: notes
-   On social media, arousing emotions attract attention and higher engagement, reflecting a function of emotions, namely grabbing attention

-   Content that is highly arousing and negative gets higher engagement, typically, this is moralizing and conflictual content

-   So we would also expect misinformation to be embedded in such emotional dynamics, anger, and intergroup hate

-   Where a major concern is not just how many people believe in it but secondary effects, such as loss in trust, growing affective polarization, and so on.
:::

# What are the effects of misinformation on social media discussions?

::: notes
-   Therefore, we were wondering what the effects of misinformation are on online discussions, do they trigger conflict and anger, and does this then lead to higher engagement?
:::

## But: measurement matters!

::: columns
::: {.column width="40%"}
::: fragment
![](images/review-table.png){width="1000"}
:::
:::

::: {.column width="60%"}
![](images/newsguard-approaches.png){width="1000"}

::: fragment
$\rightarrow$ How does this influence downstream research results?

$\rightarrow$ How volatile is NewsGuard?
:::
:::
:::

::: footer
Luehring, Lasser et al., (*in prep.*)
:::

::: notes
-   When measuring misinformation, researchers have to make multiple decisions which majorly affect the sample

-   For multiple reasons, it is really hard to identify misinformation, leading to researchers either picking outright falsehoods as factchecked stories or a few bad domains compared to a few good domains

-   However, research has shown that the grey-area content may be more widely spread and more dangerous

-   If you broaden the focus on bad information to include any content that might be misleading even if it does not involve outright falsehoods and fabrications, bad information is not easy to identify - by misinformation researchers or anyone else
:::

## Problems with existing emotions and misinformation social media studies

::: columns
::: {.column width="50%"}
::: fragment
1.  Misinformation is often measured as clearly true or false instances,

        -   neglecting less extreme types,

        -   making it hard to isolate effects of misinformation
:::
:::

::: {.column width="50%"}
::: fragment
2.  Different effects of emotions are overlooked

        -   mixing up emotional reactions with prior state, stimuli, etc.,

        -   ignoring the function of emotions,

        -   by measuring positive and negative sentiment only.
:::
:::
:::

::: footer
Allen et al., [2024](https://www.science.org/doi/10.1126/science.adk3451); van der Linden & Krychenko, [2024](https://www.science.org/doi/10.1126/science.adp9117)
:::

::: notes
We identified two problems that we wanted to tackle in this study

-   First, misinformation is often measured as clearly false, fact-checked instances, which ignores less extreme and more influential types of misinformation, for instance biased news, and it makes it hard to isolate the effects from real news

    -   So the question is, are the effects that we are observing unique to misinformation?

-   Second, emotions are functional; and the function of emotions hinges on the interaction of prior beliefs and content. Therefore, measuring only positive and negative sentiment, or mixing up emotional state with emotional reactions overlooks the contextual effects of different emotions.
:::

## Our objectives

::: columns
::: {.column width="50%"}
::: fragment
1.  Collecting a **systematic, large-scale and long-term data set** for the German-speaking context

### Continuous trustworthiness ratings by NewsGuard (#1)
:::
:::

::: {.column width="50%"}
::: fragment
2.  Approximating **causal inference** to test the effects of misinformation on online discussions

### Nonparametric matching strategy (#2)
:::
:::
:::

::: notes
So, we derived 2 major objectives:

-   First, we wanted to collect a systematic, large-scale and long-term dataset that relies on continuous trustworthiness ratings for sources, including biased but relatively trustworthy sources so that it reflects the whole spectrum of news trustworthiness

-   Second, we tried a matching approach to approximate causal inference so that we could isolate the effects of untrustworthy sources
:::

## Data collection

::: columns
::: {.column width="70%"}
*N* = 9.3M Twitter discussions following 347 German news domains (20.6M tweets total)

![](images/daily_emotions_complete.png){width="600"}
:::

::: {.column width="30%"}
NewsGuard

(0-100):

    - 93.8% trustworthy (>60)

Classification:

    - 8 emotions (Widmann & Wich, 2022; Macro F1=0.7)

    - Out-group references (Lasser at al., 2023; F1=0.8)
:::
:::

::: footer
Lasser et al., [2023](http://arxiv.org/abs/2303.00357); Widmann & Wich, [2022](https://doi.org/10.1017/pan.2022.15)
:::

::: notes
We collected roughly 9 million twitter discussions where a German news domain was shared as the first tweet, with 20M tweets in total. For those news domains, we have a trustworthiness rating from NewsGuard, therefore, we understand misinformation here as news from untrustworthy sources

-   For each tweet, we then classified 8 distinct emotions and out-group references from text
-   This plot shows the covered time frame from October 2020 to March 2022 and we can already see that anger is overall much higher
:::

# Part I: Discussions

::: notes
Now, we are zooming in on the tweets that got at least one reply and the following discussion thread
:::

## Nonparametric matching

::: columns
::: {.column width="70%"}
![](images/mahalanobis_plot_wd.png){width="700"}
:::

::: {.column width="30%"}
Nearest Neighbor and Mahalanobis distance

$\rightarrow$ *N* = 87,132
:::

Conditions: Untrustworthy vs. trustworthy (\>60)

Covariates: PO, word count, following/followers, time difference, emotions
:::

::: footer
Ho et al., [2007](https://www.cambridge.org/core/journals/political-analysis/article/matching-as-nonparametric-preprocessing-for-reducing-model-dependence-in-parametric-causal-inference/4D7E6D07C9727F5A604E5C9FCCA2DD21)
:::

::: notes
NewsGuard sets a threshold at a trustworthiness score at 60, such that sources below 60 are considered untrustworthy

We used this classification to create two conditions (trustworthy vs untrustworthy) and then applied a nonparametric matching approach to balance the dataset based on a set of covariates

Those are the political orientation of the source, the initial emotion in the tweet, following, follower and tweet counts, as well as the word count of the first tweet

We also included the time difference between the first reply and the last to control for collective emotional development

This plot shows the initial standardized mean difference between the two conditions in white dots and the balanced data in black, where we can see that by matching fitting cases, we reduced it to almost 0 for most covariates, so we literally hold them constant across the two conditions

This approach reduced the balanced dataset to 87,000 discussions
:::

## Do emotions differ based on trustworthiness?

::: columns
::: {.column width="75%"}
![](images/mean_emotion_matched-95.png){width="600"} ~Models:Â OLSÂ regressions~
:::

::: {.column width="25%"}
$\rightarrow$ More anger and out-group references

$\rightarrow$ Less joy
:::
:::

::: notes
So, do emotions differ based on trustworthiness?

Here, we can see the mean differences in emotions between trustworthy vs untrustworthy discussion threads, with emotions measured in both the whole discussion aggregated and only the first response to the stimuli

-   In both, there are significant differences in most emotions, except for enthusiasm, however, we observe substantially more anger, more out-group references and less joy in response to untrustworthy information
:::

## But the covariates?

::: columns
::: {.column width="70%"}
![](images/full_regression_coeff_matched-wd_anger_joy.png){width="600"} ~Models:Â OLSÂ regressions~
:::

::: {.column width="30%"}
Emotion in the discussion reflects emotion in news post
:::
:::

::: notes
When we take a closer look at the effect of each covariate, we see a very interesting pattern overall: The emotion in the discussion reflects emotion in news post

This effect is stronger than the trustworthiness, here at the bottom, or the political orientation of the source
:::

## But the covariates?

::: columns
::: {.column width="70%"}
![](images/anger.png){width="600"} ~Models:Â OLSÂ regressions~
:::

::: {.column width="30%"}
Emotion in the discussion reflects emotion in news post
:::
:::

::: notes
-   Here, for anger
:::

## But the covariates?

::: columns
::: {.column width="70%"}
![](images/joy.png){width="600"} ~Models:Â OLSÂ regressions~
:::

::: {.column width="30%"}
Emotion in the discussion reflects emotion in news post
:::
:::

$\rightarrow$ Trustworthiness barely predicts emotions

::: notes
-   And for joy
-   Such that trustworthiness barely seems to predict any changes in emotions in the discussion
:::

# Part II: Discussion starter

::: notes
In a second step, we wanted to zoom out again and look at the discussion starters in the unbalanced dataset and including news posts with no replies
:::

## Do posts with lower trustworthiness include more anger?

![](images/initial_emo_coeff.png){width="600"}

$\rightarrow$ Lower trustworthiness = anger

$\rightarrow$ Higher trustworthiness = joy

::: notes
We especially wanted to see if tweets with a lower trustworthiness score also included more anger, explaining why there is more anger in the discussion

And that's also what we found!

Anger decreases when trustworthiness increases

While joy increases when trustworthiness increases
:::

## Is lower trustworthiness associated with higher engagement?

::: columns
::: {.column width="70%"}
~Models:Â Zero-inflatedÂ NegativeÂ BinomialÂ (log-link)~

~Controls:Â PO,Â wordÂ count,Â following,Â initialÂ emotions~

![](images/models_zinb_estimates-se.png){width="600"}
:::

::: {.column width="30%"}
![](images/reply_distributions.png){width="300"}
:::

$\rightarrow$ Untrustworthy sources get more retweets and quotes
:::

::: footer
Zeileis et al., [2008](http://www.jstatsoft.org/v27/i08/)
:::

::: notes
Lastly, we wanted to look at the associations between trustworthiness and engagement

Here, we included the zero replies, which zero-inflated the distribution, which you can see in the top corner

-   The results of our logistic regression model show that trustworthy information generally gets more likes than untrustworthy information. And the count model shows that, when excess zeroes are excluded, a lower trustworthiness score is associated with more retweets and quote retweets

-   Bad sources getting more reshares is also in line with the FB and Instagram experiments, where removing reshares reduced the exposure to misinformation.
:::

# Conclusion (tentative)


## Emotions $\rightarrow$ emotions $\rightarrow$ engagement?

-   Sources with low trustworthiness predict anger and out-group references
-   Emotions in discussions largely reflect emotions in initial post
-   Is engagement with low trustworthiness due to covariates?

$\rightarrow$ Not the factfulness is harmful, but the content

$\rightarrow$ Misinformation is a perfect tool to spread harmful content

::: notes
-   Low trustworthiness predicts anger and conflict in discussions
-   But, emotions in discussions largely reflect emotions in initial posts
-   Therefore, we assume that misinformation includes more anger and conflict, which leads to engagement, not the trustworthiness. If we measured topics, this effect would probably largely be explained by that.
:::

## Up next

-   responses within-users (responding to trustworthy and untrustworthy posts)
-   bootstrapping
-   marginal effects plots
-   characterizing the full discussion trees
-   other classifications: topics, toxicity, morality?

::: footer
Carrella et al., [2023](https://osf.io/qx34w); Gonzalez-Bailon et al., [2010](https://doi.org/10.1057/jit.2010.2)
:::

# Thank you!

::: columns
::: {.column width="60%"}
![](logos/logos-combined.png){width="600"}
:::

::: {.column width="40%"}
:::
:::



## Is lower trustworthiness associated with higher engagement? {visibility="uncounted"}

::: columns
::: {.column width="70%"}
~Models:Â Zero-inflatedÂ NegativeÂ BinomialÂ (log-link)~

~Controls:Â PO,Â wordÂ count,Â following,Â initialÂ emotions~

![](images/models_zero_estimates-se.png){width="600"}
:::

::: {.column width="30%"}
![](images/reply_distributions.png){width="300"}
:::
:::

::: footer
Zeileis et al., [2008](http://www.jstatsoft.org/v27/i08/)
:::
